{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let us first start by importing the data. We will use the well-known data and we will apply the logistic regression. In this part we will only recognise one digit. Let us choose 1. Now let's start by importing our data and the necessary libraries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:85: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:85: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We normalize so that we only deal with numbers in the $(0,1)$ range</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now as we are only considering whether an image is 9 or not, we will modify our labels. We are putting 1 if it is number 9, and 0 otherwise.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(y!=9,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We define the number of training data and the test data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = 65000\n",
    "m_test = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We then divide our data accordingly. But there is one problem here. Since our data is arranged, meaning that the images containes 0's images for a few thousand, and then 1 etc. Therefore if we don't shuffle, then our test data will consist of only 9 images and we will not be training for 9 images enough. Therefore before we go any further, we need to make sure that we shuffle the data. We need to be careful as the indexing is really important here.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X[0:m_train].T # We prefer column vectors that is why we take the transpose\n",
    "test = X[m_train:].T\n",
    "\n",
    "train_labels = y[0:m_train].reshape(1,m_train)\n",
    "test_labels = y[m_train:].reshape(1,m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.permutation(m_train)\n",
    "train, train_labels = train[:,rand], train_labels[:,rand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we can see below that the data is indeed shuffled properly and the digit 9 has the label 1.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train[:,8].reshape(28,28))\n",
    "print(train_labels[:,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we can use directly the code that I have added in my repository for logistic regression. For clarification I will add the code in this notebook too.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here we have the activation function as sigmoid</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We have the cost function as follows.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y, y_hat,m):\n",
    "    J = -(1./m) * (np.sum(np.multiply(np.log(y_hat),y)) + np.sum(np.multiply(np.log(1-y_hat),(1-y))))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We use the chain rule of calculus to calculate the algebraic expression for the derivative of the cost function.  $$ \\frac{\\partial J}{\\partial \\theta} = \\frac{\\partial J}{\\partial a} \\frac{\\partial a}{\\partial z} \\frac{\\partial z}{\\partial \\theta}$$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 cost:  0.6987315047816619\n",
      "Epoch:  200 cost:  0.10861957057737524\n",
      "Epoch:  400 cost:  0.10224845226504042\n",
      "Epoch:  600 cost:  0.09938965598632893\n",
      "Epoch:  800 cost:  0.09772889961586252\n",
      "Final cost: 0.09663720795832573\n"
     ]
    }
   ],
   "source": [
    "alpha = 1 # parameter of the gradient descent, sometimes known as \"learning parameter\"\n",
    "\n",
    "theta = np.random.randn(train.shape[0], 1) * 0.01\n",
    "bias = np.zeros((1,1))\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    # Forward feed\n",
    "    z = np.matmul(theta.T, train) + bias\n",
    "    a = sigmoid(z)\n",
    "    \n",
    "    # Now we can compute the cost\n",
    "    J = cost_function(train_labels,a,m_train)\n",
    "    \n",
    "    #Â With the idea of backpropagation, we compute the derivatives\n",
    "    d_theta = (1/m_train) * np.matmul(train,(a-train_labels).T)\n",
    "    d_bias = (1/m_train) * np.sum(a-train_labels, axis=1, keepdims=True)\n",
    "    \n",
    "    # We directly do the gradient descent \n",
    "    theta = theta - alpha * d_theta\n",
    "    bias = bias - alpha * d_bias\n",
    "\n",
    "    if (i % 200 == 0):\n",
    "        print(\"Epoch: \", i, \"cost: \", J)\n",
    "\n",
    "print(\"Final cost:\", J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now with these values of $\\theta$ and the bias, we apply one more forward propagation to have the outputs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3919  228]\n",
      " [  72  781]]\n"
     ]
    }
   ],
   "source": [
    "z = np.matmul(theta.T, test) + bias\n",
    "a = sigmoid(z)\n",
    "\n",
    "predictions = (a>0.5)[0,:]\n",
    "labels = (test_labels == 1)[0,:]\n",
    "\n",
    "print(confusion_matrix(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see that we have been correct most of the time. Let us use sklearn utilities one more time for a better result analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.95      0.96      4147\n",
      "        True       0.77      0.92      0.84       853\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.88      0.93      0.90      5000\n",
      "weighted avg       0.95      0.94      0.94      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This is a working model that will recognise only one digit with using one neuron i.e. logistic regression.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
